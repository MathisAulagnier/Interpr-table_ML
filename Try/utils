# Importations n√©cessaires
import pandas as pd
import numpy as np
import joblib # Ou pickle, selon le format de sauvegarde du mod√®le
import pickle 

# Mod√®les de scikit-learn
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.exceptions import NotFittedError

# Anuler les avertissements de scikit-learn
import warnings
warnings.filterwarnings("ignore", category=UserWarning, module="sklearn")

# LIME
try:
    import lime
    import lime.lime_tabular
    LIME_AVAILABLE = True
except ImportError:
    print("Avertissement : La biblioth√®que LIME n'est pas install√©e. La fonctionnalit√© global_lime_weights ne sera pas disponible.")
    LIME_AVAILABLE = False

# RiskSLIM (approximation avec imodels)
try:
    from imodels import SLIMClassifier # Ou RiskSlimClassifier si vous l'avez
    RISKSLIM_AVAILABLE = True
except ImportError:
    print("Avertissement : La biblioth√®que imodels (pour SLIMClassifier) n'est pas install√©e. La fonctionnalit√© train_riskslim_surrogate ne sera pas disponible.")
    RISKSLIM_AVAILABLE = False

# Visualisation
import matplotlib.pyplot as plt
import seaborn as sns

# Fonctions utilitaires pour charger les donn√©es et le mod√®le (√† adapter par l'utilisateur)
def load_data(csv_path):
    """
    Charge les donn√©es √† partir d'un fichier CSV.
    Pour l'exemple, cette fonction retourne un DataFrame vide.
    L'utilisateur devra remplacer cela par sa propre logique de chargement.
    """
    print(f"Chargement des donn√©es depuis {csv_path}...")
    try:
        return pd.read_csv(csv_path)
    except FileNotFoundError:
        print(f"Erreur : Fichier {csv_path} non trouv√©.")
        return pd.DataFrame() # Retourne un DataFrame vide en cas d'erreur

def load_blackbox_model(model_path):
    """
    Charge un mod√®le bo√Æte noire √† partir d'un fichier .pkl.
    Pour l'exemple, cette fonction retourne None.
    L'utilisateur devra remplacer cela par sa propre logique de chargement.
    """
    print(f"Chargement du mod√®le bo√Æte noire depuis {model_path}...")
    try:
        # Essayer avec joblib d'abord
        return joblib.load(model_path)
    except Exception:
        try:
            # Essayer avec pickle si joblib √©choue
            with open(model_path, 'rb') as f:
                return pickle.load(f)
        except FileNotFoundError:
            print(f"Erreur : Fichier mod√®le {model_path} non trouv√©.")
            return None
        except Exception as e:
            print(f"Erreur lors du chargement du mod√®le avec joblib et pickle: {e}")
            return None

# --- A. Distillation Globale ---

def distill_with_logistic_regression(X, blackbox_model):
    """
    Distille les connaissances d'un mod√®le bo√Æte noire en utilisant une R√©gression Logistique.

    Args:
        X (pd.DataFrame): Les donn√©es d'entr√©e.
        blackbox_model: Le mod√®le bo√Æte noire pr√©-entra√Æn√©.

    Returns:
        LogisticRegression: Le mod√®le de r√©gression logistique entra√Æn√© (mod√®le surrogate).
                             Retourne None si le mod√®le bo√Æte noire n'est pas entra√Æn√© ou si une erreur se produit.
    """
    print("Distillation globale avec R√©gression Logistique...")
    if not hasattr(blackbox_model, "predict_proba") and not hasattr(blackbox_model, "predict"):
        print("Erreur : Le mod√®le bo√Æte noire ne poss√®de ni m√©thode 'predict_proba' ni 'predict'.")
        return None

    try:
        # G√©n√©rer les pseudo-labels √† partir du mod√®le bo√Æte noire
        if hasattr(blackbox_model, 'predict_proba'):
            # Pour les probl√®mes de classification avec probabilit√©s
            y_distilled_proba = blackbox_model.predict_proba(X)
            # Prendre la classe avec la plus haute probabilit√© comme pseudo-label
            y_distilled = np.argmax(y_distilled_proba, axis=1)
        else:
            # Pour les mod√®les qui ne sortent que les pr√©dictions directes
            y_distilled = blackbox_model.predict(X)
        
        print(f"Nombre de pseudo-labels g√©n√©r√©s : {len(y_distilled)}")
        if len(np.unique(y_distilled)) < 2:
            print("Avertissement : Les pseudo-labels ne contiennent qu'une seule classe. La r√©gression logistique pourrait ne pas bien s'entra√Æner.")

        # Entra√Æner le mod√®le de r√©gression logistique
        surrogate_model = LogisticRegression(solver='liblinear', random_state=42) # Ajout de random_state pour la reproductibilit√©
        surrogate_model.fit(X, y_distilled)
        print("Mod√®le de R√©gression Logistique distill√© entra√Æn√©.")
        return surrogate_model

    except NotFittedError:
        print("Erreur : Le mod√®le bo√Æte noire n'est pas entra√Æn√©. Veuillez l'entra√Æner avant la distillation.")
        return None
    except Exception as e:
        print(f"Une erreur est survenue lors de la distillation avec la r√©gression logistique : {e}")
        return None


def distill_with_decision_tree(X, blackbox_model, max_depth=3):
    """
    Distille les connaissances d'un mod√®le bo√Æte noire en utilisant un Arbre de D√©cision.

    Args:
        X (pd.DataFrame): Les donn√©es d'entr√©e.
        blackbox_model: Le mod√®le bo√Æte noire pr√©-entra√Æn√©.
        max_depth (int): La profondeur maximale de l'arbre de d√©cision.

    Returns:
        DecisionTreeClassifier: Le mod√®le d'arbre de d√©cision entra√Æn√© (mod√®le surrogate).
                                Retourne None si le mod√®le bo√Æte noire n'est pas entra√Æn√© ou si une erreur se produit.
    """
    print(f"Distillation globale avec Arbre de D√©cision (max_depth={max_depth})...")
    if not hasattr(blackbox_model, "predict_proba") and not hasattr(blackbox_model, "predict"):
        print("Erreur : Le mod√®le bo√Æte noire ne poss√®de ni m√©thode 'predict_proba' ni 'predict'.")
        return None

    try:
        # G√©n√©rer les pseudo-labels
        if hasattr(blackbox_model, 'predict_proba'):
            y_distilled_proba = blackbox_model.predict_proba(X)
            y_distilled = np.argmax(y_distilled_proba, axis=1)
        else:
            y_distilled = blackbox_model.predict(X)

        print(f"Nombre de pseudo-labels g√©n√©r√©s : {len(y_distilled)}")
        if len(np.unique(y_distilled)) < 2:
             print("Avertissement : Les pseudo-labels ne contiennent qu'une seule classe. L'arbre de d√©cision pourrait ne pas bien s'entra√Æner.")


        # Entra√Æner le mod√®le d'arbre de d√©cision
        surrogate_model = DecisionTreeClassifier(max_depth=max_depth, random_state=42)
        surrogate_model.fit(X, y_distilled)
        print("Mod√®le d'Arbre de D√©cision distill√© entra√Æn√©.")
        return surrogate_model

    except NotFittedError:
        print("Erreur : Le mod√®le bo√Æte noire n'est pas entra√Æn√©. Veuillez l'entra√Æner avant la distillation.")
        return None
    except Exception as e:
        print(f"Une erreur est survenue lors de la distillation avec l'arbre de d√©cision : {e}")
        return None

# --- B. LIME Globalis√© ---

def global_lime_weights(X, blackbox_model, feature_names, num_samples_lime=100, num_features_lime=None, mode='classification'):
    """
    Calcule l'importance globale des features en agr√©geant les explications LIME locales.

    Args:
        X (pd.DataFrame): Les donn√©es d'entr√©e.
        blackbox_model: Le mod√®le bo√Æte noire pr√©-entra√Æn√©.
        feature_names (list): Liste des noms des features.
        num_samples_lime (int): Nombre d'√©chantillons √† expliquer avec LIME.
                                Un sous-ensemble de X sera utilis√© si X est plus grand.
        num_features_lime (int, optionnel): Nombre de features √† inclure dans chaque explication LIME.
                                            Par d√©faut, toutes les features.
        mode (str): 'classification' ou 'regression'.

    Returns:
        pd.Series: Une s√©rie Pandas avec l'importance moyenne (absolue) des features,
                   tri√©e par importance d√©croissante. Retourne None si LIME n'est pas disponible
                   ou si une erreur se produit.
    """
    if not LIME_AVAILABLE:
        print("Erreur : LIME n'est pas disponible. Impossible de calculer les poids LIME globaux.")
        return None
    
    print("Calcul des poids LIME globaux...")
    if num_features_lime is None:
        num_features_lime = len(feature_names)

    # S'assurer que X est un np.array pour LIME
    if isinstance(X, pd.DataFrame):
        X_lime = X.values
    else:
        X_lime = X # Supposons que c'est d√©j√† un numpy array

    # D√©terminer la fonction de pr√©diction pour LIME
    if mode == 'classification':
        if not hasattr(blackbox_model, 'predict_proba'):
            print("Erreur : Pour LIME en mode classification, le mod√®le bo√Æte noire doit avoir une m√©thode 'predict_proba'.")
            return None
        predict_fn = blackbox_model.predict_proba
    elif mode == 'regression':
        if not hasattr(blackbox_model, 'predict'):
            print("Erreur : Pour LIME en mode r√©gression, le mod√®le bo√Æte noire doit avoir une m√©thode 'predict'.")
            return None
        predict_fn = blackbox_model.predict
    else:
        print(f"Erreur : Mode LIME '{mode}' non reconnu. Utilisez 'classification' ou 'regression'.")
        return None

    try:
        explainer = lime.lime_tabular.LimeTabularExplainer(
            training_data=X_lime,
            feature_names=feature_names,
            class_names=None, # Peut √™tre sp√©cifi√© si vous avez des noms de classes
            mode=mode,
            random_state=42
        )

        all_weights = pd.DataFrame(columns=feature_names)
        
        # S√©lectionner un sous-ensemble d'√©chantillons si X est grand
        if num_samples_lime > X_lime.shape[0]:
            print(f"Avertissement : num_samples_lime ({num_samples_lime}) est sup√©rieur au nombre d'√©chantillons disponibles ({X_lime.shape[0]}). Utilisation de tous les √©chantillons.")
            samples_to_explain = X_lime
        else:
            np.random.seed(42) # Pour la reproductibilit√© de l'√©chantillonnage
            sample_indices = np.random.choice(X_lime.shape[0], num_samples_lime, replace=False)
            samples_to_explain = X_lime[sample_indices]

        print(f"G√©n√©ration de {samples_to_explain.shape[0]} explications LIME locales...")
        for i in range(samples_to_explain.shape[0]):
            instance = samples_to_explain[i]
            # Pour la classification, LIME explique souvent la classe pr√©dite ou une classe sp√©cifique.
            # Ici, nous expliquons la premi√®re classe (ou la classe positive si binaire) par d√©faut.
            # Vous pourriez vouloir adapter cela, par exemple, expliquer la classe pr√©dite par blackbox_model.
            top_labels = 1 if mode == 'classification' else None

            explanation = explainer.explain_instance(
                data_row=instance,
                predict_fn=predict_fn,
                num_features=num_features_lime,
                top_labels=top_labels 
            )
            
            # Extraire les poids pour la premi√®re (ou unique) classe expliqu√©e
            weights_dict = dict(explanation.as_list(label=explanation.available_labels()[0]))
            
            # Cr√©er une ligne pour le DataFrame all_weights
            current_weights = pd.Series(index=feature_names, dtype=float).fillna(0.0)
            for feature_idx, weight in weights_dict.items(): # LIME retourne des indices de feature ou des noms pars√©s
                # Essayer de mapper l'index ou le nom de feature LIME au nom original
                # C'est un peu d√©licat car LIME peut modifier les noms (ex: "feature <= val")
                # Pour cet exemple, on suppose que les noms de features sont directement utilisables ou que l'index est correct.
                # Une approche plus robuste impliquerait de parser les noms de features retourn√©s par LIME.
                # Pour LimeTabularExplainer, les poids sont associ√©s aux noms de features originaux s'ils sont bien pass√©s.
                if isinstance(feature_idx, int) and feature_idx < len(feature_names): # Si c'est un index
                     current_weights[feature_names[feature_idx]] = weight
                elif isinstance(feature_idx, str): # Si c'est un nom (peut √™tre pars√© par LIME)
                    # Tentative de faire correspondre le nom de feature exact
                    if feature_idx in feature_names:
                        current_weights[feature_idx] = weight
                    else:
                        # Si le nom n'est pas exact, on essaie de trouver une correspondance partielle (simpliste)
                        # Cela peut n√©cessiter une logique plus avanc√©e pour les features cat√©gorielles ou discr√©tis√©es par LIME
                        for fn in feature_names:
                            if fn in feature_idx: # ex: "Age" est dans "Age <= 30"
                                current_weights[fn] = current_weights.get(fn, 0.0) + weight # Accumuler si plusieurs conditions sur la m√™me feature
                                break
            
            all_weights = pd.concat([all_weights, pd.DataFrame([current_weights])], ignore_index=True)


        # Calculer l'importance moyenne absolue
        # Remplacer les NaN potentiels par 0 avant de calculer la moyenne
        global_feature_importance = all_weights.fillna(0).abs().mean().sort_values(ascending=False)
        print("Poids LIME globaux calcul√©s.")
        return global_feature_importance

    except NotFittedError:
        print("Erreur : Le mod√®le bo√Æte noire n'est pas entra√Æn√©. Veuillez l'entra√Æner avant d'utiliser LIME.")
        return None
    except Exception as e:
        print(f"Une erreur est survenue lors du calcul des poids LIME globaux : {e}")
        import traceback
        traceback.print_exc()
        return None


def plot_lime_weights(global_weights, top_n=15):
    """
    Visualise les poids LIME globaux sous forme de barplot.

    Args:
        global_weights (pd.Series): S√©rie Pandas avec l'importance moyenne des features.
        top_n (int): Nombre de features les plus importantes √† afficher.
    """
    if global_weights is None or global_weights.empty:
        print("Aucun poids LIME √† visualiser.")
        return

    print(f"Visualisation des {top_n} features les plus importantes (LIME global)...")
    plt.figure(figsize=(10, top_n * 0.3 + 2)) # Ajuster la taille dynamiquement
    sns.barplot(x=global_weights.head(top_n).values, y=global_weights.head(top_n).index, palette="viridis")
    plt.title(f'Importance Globale des Features (Moyenne des Poids LIME Absolus) - Top {top_n}')
    plt.xlabel('Importance Moyenne Absolue')
    plt.ylabel('Feature')
    plt.tight_layout()
    plt.show()

# --- C. RiskSLIM (ou SLIM approximatif) ---

def train_riskslim_surrogate(X, blackbox_model):
    """
    Entra√Æne un mod√®le SLIM (Simplified Linear Integer Model) approximatif
    en utilisant imodels.SLIMClassifier comme surrogate pour RiskSLIM.

    Args:
        X (pd.DataFrame): Les donn√©es d'entr√©e.
        blackbox_model: Le mod√®le bo√Æte noire pr√©-entra√Æn√©.

    Returns:
        imodels.SLIMClassifier: Le mod√®le SLIM entra√Æn√©.
                                Retourne None si imodels n'est pas disponible,
                                si le mod√®le bo√Æte noire n'est pas entra√Æn√©, ou en cas d'erreur.
    """
    if not RISKSLIM_AVAILABLE:
        print("Erreur : imodels (pour SLIMClassifier) n'est pas disponible. Impossible d'entra√Æner le surrogate RiskSLIM.")
        return None

    print("Entra√Ænement du surrogate RiskSLIM (avec imodels.SLIMClassifier)... Veuillez patienter, cela peut √™tre long.")
    
    if not hasattr(blackbox_model, "predict"):
        print("Erreur : Le mod√®le bo√Æte noire doit avoir une m√©thode 'predict' pour RiskSLIM.")
        return None

    try:
        # G√©n√©rer les pseudo-labels (pr√©dictions directes)
        y_distilled = blackbox_model.predict(X)
        
        print(f"Nombre de pseudo-labels g√©n√©r√©s : {len(y_distilled)}")
        if len(np.unique(y_distilled)) < 2:
             print("Avertissement : Les pseudo-labels ne contiennent qu'une seule classe. SLIMClassifier pourrait ne pas bien s'entra√Æner.")


        # SLIMClassifier s'attend √† des labels -1, 1 ou 0, 1.
        # Si les labels sont autres (ex: 0 et 2), il faut les mapper.
        # Pour cet exemple, on suppose que les labels sont d√©j√† compatibles (ex: 0 et 1).
        # Si ce n'est pas le cas, ajoutez une √©tape de remappage ici.
        # Exemple de remappage si les labels sont {a, b}:
        # unique_labels = np.unique(y_distilled)
        # if not ( (0 in unique_labels and 1 in unique_labels and len(unique_labels) == 2) or \
        #          (-1 in unique_labels and 1 in unique_labels and len(unique_labels) == 2) ):
        #     print(f"Avertissement: SLIMClassifier pr√©f√®re les labels (0,1) ou (-1,1). Labels actuels: {unique_labels}. Tentative de mappage...")
        #     # Exemple simple: mapper le premier label √† 0 et le second √† 1
        #     if len(unique_labels) == 2:
        #         y_distilled = np.where(y_distilled == unique_labels[0], 0, 1)
        #     else:
        #         print("Erreur: Trop de classes ou une seule classe pour un mappage simple √† (0,1). SLIM pourrait √©chouer.")


        # Entra√Æner le mod√®le SLIM
        # Les hyperparam√®tres de SLIMClassifier peuvent n√©cessiter un ajustement.
        # alpha est le param√®tre de r√©gularisation L0 (complexit√© du mod√®le).
        # lambda_1 est le param√®tre de r√©gularisation L1 (coefficients).
        # Par d√©faut, SLIMClassifier utilise CPLEX ou un solveur MIP. S'ils ne sont pas install√©s,
        # il peut utiliser une heuristique ou √©chouer.
        # Pour une version plus simple et rapide, on peut utiliser peu d'it√©rations,
        # mais cela peut affecter la qualit√©.
        surrogate_model = SLIMClassifier(alpha=0.01, n_epochs=100, random_state=42) # n_epochs pour l'heuristique interne si pas de solveur MIP
        
        # SLIMClassifier de imodels peut √™tre sensible au type de donn√©es.
        # S'assurer que X est un numpy array de float.
        X_slim = X.values.astype(float) if isinstance(X, pd.DataFrame) else np.array(X).astype(float)
        
        surrogate_model.fit(X_slim, y_distilled)
        print("Mod√®le surrogate RiskSLIM (SLIMClassifier) entra√Æn√©.")
        print("Coefficients du mod√®le SLIM :")
        # Afficher les coefficients (le "scorecard")
        for i, feature_name in enumerate(X.columns if isinstance(X, pd.DataFrame) else [f"feature_{j}" for j in range(X_slim.shape[1])]):
            if surrogate_model.model.coef_[0, i] != 0: # Afficher seulement les features avec des poids non nuls
                print(f"  {feature_name}: {surrogate_model.model.coef_[0, i]:.2f}")
        print(f"  Intercept: {surrogate_model.model.intercept_[0]:.2f}")
        
        return surrogate_model

    except NotFittedError:
        print("Erreur : Le mod√®le bo√Æte noire n'est pas entra√Æn√©. Veuillez l'entra√Æner avant d'utiliser RiskSLIM.")
        return None
    except Exception as e:
        print(f"Une erreur est survenue lors de l'entra√Ænement du surrogate RiskSLIM : {e}")
        import traceback
        traceback.print_exc()
        # SLIMClassifier peut parfois avoir des probl√®mes avec certains solveurs ou types de donn√©es.
        print("Conseil : V√©rifiez que les donn√©es d'entr√©e X sont num√©riques et que les pseudo-labels y_distilled sont binaires (0/1 ou -1/1).")
        print("Si vous utilisez un solveur MIP comme CPLEX ou Gurobi, assurez-vous qu'il est correctement install√© et licenci√©.")
        return None

# --- üß™ Fonctions d'√©valuation bonus ---

def evaluate_accuracy(model, X, y_true):
    """
    √âvalue l'accuracy d'un mod√®le par rapport aux vrais labels.

    Args:
        model: Le mod√®le √† √©valuer (doit avoir une m√©thode `predict`).
        X (pd.DataFrame): Les donn√©es d'entr√©e.
        y_true (pd.Series or np.array): Les vrais labels.

    Returns:
        float: L'accuracy du mod√®le. Retourne None en cas d'erreur.
    """
    if model is None:
        print("Erreur d'√©valuation : Le mod√®le fourni est None.")
        return None
    if not hasattr(model, "predict"):
        print(f"Erreur d'√©valuation : Le mod√®le {type(model)} ne poss√®de pas de m√©thode 'predict'.")
        return None
        
    print(f"√âvaluation de l'accuracy du mod√®le {type(model).__name__}...")
    try:
        y_pred = model.predict(X)
        acc = accuracy_score(y_true, y_pred)
        print(f"Accuracy par rapport √† y_true : {acc:.4f}")
        return acc
    except Exception as e:
        print(f"Erreur lors de l'√©valuation de l'accuracy : {e}")
        return None

def evaluate_fidelity(model, blackbox_model, X):
    """
    √âvalue la fid√©lit√© d'un mod√®le surrogate par rapport aux pr√©dictions du mod√®le bo√Æte noire.

    Args:
        model: Le mod√®le surrogate √† √©valuer (doit avoir une m√©thode `predict`).
        blackbox_model: Le mod√®le bo√Æte noire de r√©f√©rence.
        X (pd.DataFrame): Les donn√©es d'entr√©e.

    Returns:
        float: La fid√©lit√© du mod√®le surrogate (accuracy par rapport aux pr√©dictions de la bo√Æte noire).
               Retourne None en cas d'erreur.
    """
    if model is None:
        print("Erreur d'√©valuation de la fid√©lit√© : Le mod√®le surrogate fourni est None.")
        return None
    if blackbox_model is None:
        print("Erreur d'√©valuation de la fid√©lit√© : Le mod√®le bo√Æte noire fourni est None.")
        return None
    if not hasattr(model, "predict"):
        print(f"Erreur d'√©valuation de la fid√©lit√© : Le mod√®le surrogate {type(model)} ne poss√®de pas de m√©thode 'predict'.")
        return None
    if not hasattr(blackbox_model, "predict"):
        print(f"Erreur d'√©valuation de la fid√©lit√© : Le mod√®le bo√Æte noire {type(blackbox_model)} ne poss√®de pas de m√©thode 'predict'.")
        return None

    print(f"√âvaluation de la fid√©lit√© du mod√®le {type(model).__name__} par rapport √† {type(blackbox_model).__name__}...")
    try:
        # Pr√©dictions du mod√®le surrogate
        y_pred_surrogate = model.predict(X)
        
        # Pr√©dictions du mod√®le bo√Æte noire (pseudo-labels)
        y_pred_blackbox = blackbox_model.predict(X)
        
        fidelity = accuracy_score(y_pred_blackbox, y_pred_surrogate)
        print(f"Fid√©lit√© (similarit√© des pr√©dictions) : {fidelity:.4f}")
        return fidelity
    except Exception as e:
        print(f"Erreur lors de l'√©valuation de la fid√©lit√© : {e}")
        return None

# --- Exemple d'utilisation (√† d√©commenter et adapter par l'utilisateur) ---
if __name__ == '__main__':
    print("--- D√©but de l'exemple d'utilisation ---")

    # 0. Pr√©paration des donn√©es et du mod√®le (simulation)
    # L'utilisateur doit remplacer ces chemins par les siens.
    # Assurez-vous que 'dummy_data.csv' et 'dummy_blackbox_model.pkl' existent
    # ou remplacez par vos propres fichiers.

    # Cr√©ation de donn√©es et d'un mod√®le factices pour l'exemple
    from sklearn.datasets import make_classification
    from sklearn.model_selection import train_test_split
    from sklearn.ensemble import RandomForestClassifier # Mod√®le bo√Æte noire exemple

    X_data, y_data = make_classification(n_samples=500, n_features=10, n_informative=5, n_redundant=2, random_state=42)
    X_df = pd.DataFrame(X_data, columns=[f'feature_{i}' for i in range(X_data.shape[1])])
    y_series = pd.Series(y_data, name='target')

    # Sauvegarder les donn√©es factices
    X_df.to_csv('dummy_data.csv', index=False)
    # y_series est utilis√© pour l'√©valuation de l'accuracy, pas directement par les fonctions de distillation.

    # Entra√Æner et sauvegarder un mod√®le bo√Æte noire factice
    blackbox_model_instance = RandomForestClassifier(n_estimators=50, random_state=42)
    blackbox_model_instance.fit(X_df, y_series)
    joblib.dump(blackbox_model_instance, 'dummy_blackbox_model.pkl')
    print("Donn√©es et mod√®le bo√Æte noire factices cr√©√©s et sauvegard√©s ('dummy_data.csv', 'dummy_blackbox_model.pkl').")

    # Chemins vers les fichiers (√† adapter par l'utilisateur)
    csv_file_path = 'dummy_data.csv' # Remplacez par le chemin de votre fichier CSV
    model_file_path = 'dummy_blackbox_model.pkl' # Remplacez par le chemin de votre fichier .pkl

    # Charger les donn√©es et le mod√®le
    X_input = load_data(csv_file_path)
    blackbox_model_loaded = load_blackbox_model(model_file_path)

    # Noms des features (important pour LIME)
    if not X_input.empty:
        feature_names_list = X_input.columns.tolist()
    else:
        feature_names_list = [] # ou une liste par d√©faut si X_input est vide

    # V√©rifier que tout est charg√© correctement avant de continuer
    if X_input.empty or blackbox_model_loaded is None or not feature_names_list:
        print("\nErreur lors du chargement des donn√©es ou du mod√®le. Arr√™t de l'exemple.")
    else:
        print(f"\nDonn√©es charg√©es : {X_input.shape}")
        print(f"Mod√®le bo√Æte noire charg√© : {type(blackbox_model_loaded).__name__}")
        print(f"Noms des features : {feature_names_list}")

        # 1. Distillation Globale
        print("\n--- Test de la Distillation Globale ---")
        lr_surrogate = distill_with_logistic_regression(X_input, blackbox_model_loaded)
        if lr_surrogate:
            print(f"Mod√®le de R√©gression Logistique distill√© : {lr_surrogate}")
            evaluate_accuracy(lr_surrogate, X_input, y_series) # y_series sont les vrais labels
            evaluate_fidelity(lr_surrogate, blackbox_model_loaded, X_input)

        dt_surrogate = distill_with_decision_tree(X_input, blackbox_model_loaded, max_depth=4)
        if dt_surrogate:
            print(f"\nMod√®le d'Arbre de D√©cision distill√© : {dt_surrogate}")
            evaluate_accuracy(dt_surrogate, X_input, y_series)
            evaluate_fidelity(dt_surrogate, blackbox_model_loaded, X_input)
            
            # Visualisation de l'arbre (optionnel, n√©cessite graphviz)
            try:
                from sklearn.tree import export_graphviz
                import graphviz
                dot_data = export_graphviz(dt_surrogate, out_file=None, 
                                         feature_names=feature_names_list,  
                                         class_names=[str(i) for i in np.unique(y_series)], # Assurez-vous que les noms de classe sont des str
                                         filled=True, rounded=True,  
                                         special_characters=True)  
                graph = graphviz.Source(dot_data)  
                graph.render("decision_tree_surrogate") # Sauvegarde en fichier
                print("\nPour visualiser l'arbre, vous pouvez d√©commenter graph.render() ou afficher graph directement si dans un notebook.")
                # Dans un notebook Jupyter, `graph` s'afficherait.
            except ImportError:
                print("\nGraphviz non install√©. Impossible de visualiser l'arbre de d√©cision.")
            except Exception as e_graph:
                print(f"\nErreur lors de la tentative de visualisation de l'arbre : {e_graph}")


        # 2. LIME Globalis√©
        print("\n--- Test de LIME Globalis√© ---")
        if LIME_AVAILABLE:
            # Utiliser un plus petit nombre d'√©chantillons pour l'exemple pour que ce soit plus rapide
            # S'assurer que X_input n'est pas vide
            num_lime_expl = min(50, X_input.shape[0]) if not X_input.empty else 0
            
            if num_lime_expl > 0:
                 # D√©terminer le mode bas√© sur la sortie du mod√®le (simpliste)
                try:
                    pred_sample = blackbox_model_loaded.predict(X_input.head(1))
                    if hasattr(blackbox_model_loaded, 'predict_proba'):
                         lime_mode = 'classification'
                    elif isinstance(pred_sample[0], (int, str, bool, np.integer, np.bool_)): # Suppose classification si discret
                         lime_mode = 'classification' # Peut n√©cessiter predict_proba pour LIME
                         print("Avertissement LIME: Le mod√®le n'a pas predict_proba, LIME pour classification pourrait √™tre moins optimal.")
                    else: # Suppose r√©gression si continu
                         lime_mode = 'regression'
                except Exception:
                    lime_mode = 'classification' # Par d√©faut
                    print("Avertissement LIME: Impossible de d√©terminer le mode automatiquement, utilisation de 'classification'.")


                global_weights_lime = global_lime_weights(X_input, blackbox_model_loaded, 
                                                          feature_names_list, 
                                                          num_samples_lime=num_lime_expl,
                                                          mode=lime_mode)
                if global_weights_lime is not None and not global_weights_lime.empty:
                    print("\nPoids LIME Globaux (Top 5) :")
                    print(global_weights_lime.head())
                    plot_lime_weights(global_weights_lime, top_n=10)
                else:
                    print("Aucun poids LIME global n'a √©t√© calcul√©.")
            else:
                print("Pas assez d'√©chantillons dans X_input pour ex√©cuter LIME globalis√©.")
        else:
            print("LIME non disponible, test saut√©.")

        # 3. RiskSLIM (approximatif)
        print("\n--- Test de RiskSLIM (approximatif) ---")
        if RISKSLIM_AVAILABLE:
            riskslim_surrogate = train_riskslim_surrogate(X_input, blackbox_model_loaded)
            if riskslim_surrogate:
                print(f"\nMod√®le RiskSLIM (approximatif) entra√Æn√© : {riskslim_surrogate}")
                evaluate_accuracy(riskslim_surrogate, X_input.values.astype(float), y_series) # SLIM peut n√©cessiter un array numpy
                evaluate_fidelity(riskslim_surrogate, blackbox_model_loaded, X_input.values.astype(float))
        else:
            print("imodels (pour SLIMClassifier) non disponible, test saut√©.")

    print("\n--- Fin de l'exemple d'utilisation ---")