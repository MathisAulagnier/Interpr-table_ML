# Importations nécessaires
import pandas as pd
import numpy as np
import joblib # Ou pickle, selon le format de sauvegarde du modèle
import pickle 

# Modèles de scikit-learn
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.exceptions import NotFittedError

# Anuler les avertissements de scikit-learn
import warnings
warnings.filterwarnings("ignore", category=UserWarning, module="sklearn")

# LIME
try:
    import lime
    import lime.lime_tabular
    LIME_AVAILABLE = True
except ImportError:
    print("Avertissement : La bibliothèque LIME n'est pas installée. La fonctionnalité global_lime_weights ne sera pas disponible.")
    LIME_AVAILABLE = False

# RiskSLIM (approximation avec imodels)
try:
    from imodels import SLIMClassifier # Ou RiskSlimClassifier si vous l'avez
    RISKSLIM_AVAILABLE = True
except ImportError:
    print("Avertissement : La bibliothèque imodels (pour SLIMClassifier) n'est pas installée. La fonctionnalité train_riskslim_surrogate ne sera pas disponible.")
    RISKSLIM_AVAILABLE = False

# Visualisation
import matplotlib.pyplot as plt
import seaborn as sns

# Fonctions utilitaires pour charger les données et le modèle (à adapter par l'utilisateur)
def load_data(csv_path):
    """
    Charge les données à partir d'un fichier CSV.
    Pour l'exemple, cette fonction retourne un DataFrame vide.
    L'utilisateur devra remplacer cela par sa propre logique de chargement.
    """
    print(f"Chargement des données depuis {csv_path}...")
    try:
        return pd.read_csv(csv_path)
    except FileNotFoundError:
        print(f"Erreur : Fichier {csv_path} non trouvé.")
        return pd.DataFrame() # Retourne un DataFrame vide en cas d'erreur

def load_blackbox_model(model_path):
    """
    Charge un modèle boîte noire à partir d'un fichier .pkl.
    Pour l'exemple, cette fonction retourne None.
    L'utilisateur devra remplacer cela par sa propre logique de chargement.
    """
    print(f"Chargement du modèle boîte noire depuis {model_path}...")
    try:
        # Essayer avec joblib d'abord
        return joblib.load(model_path)
    except Exception:
        try:
            # Essayer avec pickle si joblib échoue
            with open(model_path, 'rb') as f:
                return pickle.load(f)
        except FileNotFoundError:
            print(f"Erreur : Fichier modèle {model_path} non trouvé.")
            return None
        except Exception as e:
            print(f"Erreur lors du chargement du modèle avec joblib et pickle: {e}")
            return None

# --- A. Distillation Globale ---

def distill_with_logistic_regression(X, blackbox_model):
    """
    Distille les connaissances d'un modèle boîte noire en utilisant une Régression Logistique.

    Args:
        X (pd.DataFrame): Les données d'entrée.
        blackbox_model: Le modèle boîte noire pré-entraîné.

    Returns:
        LogisticRegression: Le modèle de régression logistique entraîné (modèle surrogate).
                             Retourne None si le modèle boîte noire n'est pas entraîné ou si une erreur se produit.
    """
    print("Distillation globale avec Régression Logistique...")
    if not hasattr(blackbox_model, "predict_proba") and not hasattr(blackbox_model, "predict"):
        print("Erreur : Le modèle boîte noire ne possède ni méthode 'predict_proba' ni 'predict'.")
        return None

    try:
        # Générer les pseudo-labels à partir du modèle boîte noire
        if hasattr(blackbox_model, 'predict_proba'):
            # Pour les problèmes de classification avec probabilités
            y_distilled_proba = blackbox_model.predict_proba(X)
            # Prendre la classe avec la plus haute probabilité comme pseudo-label
            y_distilled = np.argmax(y_distilled_proba, axis=1)
        else:
            # Pour les modèles qui ne sortent que les prédictions directes
            y_distilled = blackbox_model.predict(X)
        
        print(f"Nombre de pseudo-labels générés : {len(y_distilled)}")
        if len(np.unique(y_distilled)) < 2:
            print("Avertissement : Les pseudo-labels ne contiennent qu'une seule classe. La régression logistique pourrait ne pas bien s'entraîner.")

        # Entraîner le modèle de régression logistique
        surrogate_model = LogisticRegression(solver='liblinear', random_state=42) # Ajout de random_state pour la reproductibilité
        surrogate_model.fit(X, y_distilled)
        print("Modèle de Régression Logistique distillé entraîné.")
        return surrogate_model

    except NotFittedError:
        print("Erreur : Le modèle boîte noire n'est pas entraîné. Veuillez l'entraîner avant la distillation.")
        return None
    except Exception as e:
        print(f"Une erreur est survenue lors de la distillation avec la régression logistique : {e}")
        return None


def distill_with_decision_tree(X, blackbox_model, max_depth=3):
    """
    Distille les connaissances d'un modèle boîte noire en utilisant un Arbre de Décision.

    Args:
        X (pd.DataFrame): Les données d'entrée.
        blackbox_model: Le modèle boîte noire pré-entraîné.
        max_depth (int): La profondeur maximale de l'arbre de décision.

    Returns:
        DecisionTreeClassifier: Le modèle d'arbre de décision entraîné (modèle surrogate).
                                Retourne None si le modèle boîte noire n'est pas entraîné ou si une erreur se produit.
    """
    print(f"Distillation globale avec Arbre de Décision (max_depth={max_depth})...")
    if not hasattr(blackbox_model, "predict_proba") and not hasattr(blackbox_model, "predict"):
        print("Erreur : Le modèle boîte noire ne possède ni méthode 'predict_proba' ni 'predict'.")
        return None

    try:
        # Générer les pseudo-labels
        if hasattr(blackbox_model, 'predict_proba'):
            y_distilled_proba = blackbox_model.predict_proba(X)
            y_distilled = np.argmax(y_distilled_proba, axis=1)
        else:
            y_distilled = blackbox_model.predict(X)

        print(f"Nombre de pseudo-labels générés : {len(y_distilled)}")
        if len(np.unique(y_distilled)) < 2:
             print("Avertissement : Les pseudo-labels ne contiennent qu'une seule classe. L'arbre de décision pourrait ne pas bien s'entraîner.")


        # Entraîner le modèle d'arbre de décision
        surrogate_model = DecisionTreeClassifier(max_depth=max_depth, random_state=42)
        surrogate_model.fit(X, y_distilled)
        print("Modèle d'Arbre de Décision distillé entraîné.")
        return surrogate_model

    except NotFittedError:
        print("Erreur : Le modèle boîte noire n'est pas entraîné. Veuillez l'entraîner avant la distillation.")
        return None
    except Exception as e:
        print(f"Une erreur est survenue lors de la distillation avec l'arbre de décision : {e}")
        return None

# --- B. LIME Globalisé ---

def global_lime_weights(X, blackbox_model, feature_names, num_samples_lime=100, num_features_lime=None, mode='classification'):
    """
    Calcule l'importance globale des features en agrégeant les explications LIME locales.

    Args:
        X (pd.DataFrame): Les données d'entrée.
        blackbox_model: Le modèle boîte noire pré-entraîné.
        feature_names (list): Liste des noms des features.
        num_samples_lime (int): Nombre d'échantillons à expliquer avec LIME.
                                Un sous-ensemble de X sera utilisé si X est plus grand.
        num_features_lime (int, optionnel): Nombre de features à inclure dans chaque explication LIME.
                                            Par défaut, toutes les features.
        mode (str): 'classification' ou 'regression'.

    Returns:
        pd.Series: Une série Pandas avec l'importance moyenne (absolue) des features,
                   triée par importance décroissante. Retourne None si LIME n'est pas disponible
                   ou si une erreur se produit.
    """
    if not LIME_AVAILABLE:
        print("Erreur : LIME n'est pas disponible. Impossible de calculer les poids LIME globaux.")
        return None
    
    print("Calcul des poids LIME globaux...")
    if num_features_lime is None:
        num_features_lime = len(feature_names)

    # S'assurer que X est un np.array pour LIME
    if isinstance(X, pd.DataFrame):
        X_lime = X.values
    else:
        X_lime = X # Supposons que c'est déjà un numpy array

    # Déterminer la fonction de prédiction pour LIME
    if mode == 'classification':
        if not hasattr(blackbox_model, 'predict_proba'):
            print("Erreur : Pour LIME en mode classification, le modèle boîte noire doit avoir une méthode 'predict_proba'.")
            return None
        predict_fn = blackbox_model.predict_proba
    elif mode == 'regression':
        if not hasattr(blackbox_model, 'predict'):
            print("Erreur : Pour LIME en mode régression, le modèle boîte noire doit avoir une méthode 'predict'.")
            return None
        predict_fn = blackbox_model.predict
    else:
        print(f"Erreur : Mode LIME '{mode}' non reconnu. Utilisez 'classification' ou 'regression'.")
        return None

    try:
        explainer = lime.lime_tabular.LimeTabularExplainer(
            training_data=X_lime,
            feature_names=feature_names,
            class_names=None, # Peut être spécifié si vous avez des noms de classes
            mode=mode,
            random_state=42
        )

        all_weights = pd.DataFrame(columns=feature_names)
        
        # Sélectionner un sous-ensemble d'échantillons si X est grand
        if num_samples_lime > X_lime.shape[0]:
            print(f"Avertissement : num_samples_lime ({num_samples_lime}) est supérieur au nombre d'échantillons disponibles ({X_lime.shape[0]}). Utilisation de tous les échantillons.")
            samples_to_explain = X_lime
        else:
            np.random.seed(42) # Pour la reproductibilité de l'échantillonnage
            sample_indices = np.random.choice(X_lime.shape[0], num_samples_lime, replace=False)
            samples_to_explain = X_lime[sample_indices]

        print(f"Génération de {samples_to_explain.shape[0]} explications LIME locales...")
        for i in range(samples_to_explain.shape[0]):
            instance = samples_to_explain[i]
            # Pour la classification, LIME explique souvent la classe prédite ou une classe spécifique.
            # Ici, nous expliquons la première classe (ou la classe positive si binaire) par défaut.
            # Vous pourriez vouloir adapter cela, par exemple, expliquer la classe prédite par blackbox_model.
            top_labels = 1 if mode == 'classification' else None

            explanation = explainer.explain_instance(
                data_row=instance,
                predict_fn=predict_fn,
                num_features=num_features_lime,
                top_labels=top_labels 
            )
            
            # Extraire les poids pour la première (ou unique) classe expliquée
            weights_dict = dict(explanation.as_list(label=explanation.available_labels()[0]))
            
            # Créer une ligne pour le DataFrame all_weights
            current_weights = pd.Series(index=feature_names, dtype=float).fillna(0.0)
            for feature_idx, weight in weights_dict.items(): # LIME retourne des indices de feature ou des noms parsés
                # Essayer de mapper l'index ou le nom de feature LIME au nom original
                # C'est un peu délicat car LIME peut modifier les noms (ex: "feature <= val")
                # Pour cet exemple, on suppose que les noms de features sont directement utilisables ou que l'index est correct.
                # Une approche plus robuste impliquerait de parser les noms de features retournés par LIME.
                # Pour LimeTabularExplainer, les poids sont associés aux noms de features originaux s'ils sont bien passés.
                if isinstance(feature_idx, int) and feature_idx < len(feature_names): # Si c'est un index
                     current_weights[feature_names[feature_idx]] = weight
                elif isinstance(feature_idx, str): # Si c'est un nom (peut être parsé par LIME)
                    # Tentative de faire correspondre le nom de feature exact
                    if feature_idx in feature_names:
                        current_weights[feature_idx] = weight
                    else:
                        # Si le nom n'est pas exact, on essaie de trouver une correspondance partielle (simpliste)
                        # Cela peut nécessiter une logique plus avancée pour les features catégorielles ou discrétisées par LIME
                        for fn in feature_names:
                            if fn in feature_idx: # ex: "Age" est dans "Age <= 30"
                                current_weights[fn] = current_weights.get(fn, 0.0) + weight # Accumuler si plusieurs conditions sur la même feature
                                break
            
            all_weights = pd.concat([all_weights, pd.DataFrame([current_weights])], ignore_index=True)


        # Calculer l'importance moyenne absolue
        # Remplacer les NaN potentiels par 0 avant de calculer la moyenne
        global_feature_importance = all_weights.fillna(0).abs().mean().sort_values(ascending=False)
        print("Poids LIME globaux calculés.")
        return global_feature_importance

    except NotFittedError:
        print("Erreur : Le modèle boîte noire n'est pas entraîné. Veuillez l'entraîner avant d'utiliser LIME.")
        return None
    except Exception as e:
        print(f"Une erreur est survenue lors du calcul des poids LIME globaux : {e}")
        import traceback
        traceback.print_exc()
        return None


def plot_lime_weights(global_weights, top_n=15):
    """
    Visualise les poids LIME globaux sous forme de barplot.

    Args:
        global_weights (pd.Series): Série Pandas avec l'importance moyenne des features.
        top_n (int): Nombre de features les plus importantes à afficher.
    """
    if global_weights is None or global_weights.empty:
        print("Aucun poids LIME à visualiser.")
        return

    print(f"Visualisation des {top_n} features les plus importantes (LIME global)...")
    plt.figure(figsize=(10, top_n * 0.3 + 2)) # Ajuster la taille dynamiquement
    sns.barplot(x=global_weights.head(top_n).values, y=global_weights.head(top_n).index, palette="viridis")
    plt.title(f'Importance Globale des Features (Moyenne des Poids LIME Absolus) - Top {top_n}')
    plt.xlabel('Importance Moyenne Absolue')
    plt.ylabel('Feature')
    plt.tight_layout()
    plt.show()

# --- C. RiskSLIM (ou SLIM approximatif) ---

def train_riskslim_surrogate(X, blackbox_model):
    """
    Entraîne un modèle SLIM (Simplified Linear Integer Model) approximatif
    en utilisant imodels.SLIMClassifier comme surrogate pour RiskSLIM.

    Args:
        X (pd.DataFrame): Les données d'entrée.
        blackbox_model: Le modèle boîte noire pré-entraîné.

    Returns:
        imodels.SLIMClassifier: Le modèle SLIM entraîné.
                                Retourne None si imodels n'est pas disponible,
                                si le modèle boîte noire n'est pas entraîné, ou en cas d'erreur.
    """
    if not RISKSLIM_AVAILABLE:
        print("Erreur : imodels (pour SLIMClassifier) n'est pas disponible. Impossible d'entraîner le surrogate RiskSLIM.")
        return None

    print("Entraînement du surrogate RiskSLIM (avec imodels.SLIMClassifier)... Veuillez patienter, cela peut être long.")
    
    if not hasattr(blackbox_model, "predict"):
        print("Erreur : Le modèle boîte noire doit avoir une méthode 'predict' pour RiskSLIM.")
        return None

    try:
        # Générer les pseudo-labels (prédictions directes)
        y_distilled = blackbox_model.predict(X)
        
        print(f"Nombre de pseudo-labels générés : {len(y_distilled)}")
        if len(np.unique(y_distilled)) < 2:
             print("Avertissement : Les pseudo-labels ne contiennent qu'une seule classe. SLIMClassifier pourrait ne pas bien s'entraîner.")


        # SLIMClassifier s'attend à des labels -1, 1 ou 0, 1.
        # Si les labels sont autres (ex: 0 et 2), il faut les mapper.
        # Pour cet exemple, on suppose que les labels sont déjà compatibles (ex: 0 et 1).
        # Si ce n'est pas le cas, ajoutez une étape de remappage ici.
        # Exemple de remappage si les labels sont {a, b}:
        # unique_labels = np.unique(y_distilled)
        # if not ( (0 in unique_labels and 1 in unique_labels and len(unique_labels) == 2) or \
        #          (-1 in unique_labels and 1 in unique_labels and len(unique_labels) == 2) ):
        #     print(f"Avertissement: SLIMClassifier préfère les labels (0,1) ou (-1,1). Labels actuels: {unique_labels}. Tentative de mappage...")
        #     # Exemple simple: mapper le premier label à 0 et le second à 1
        #     if len(unique_labels) == 2:
        #         y_distilled = np.where(y_distilled == unique_labels[0], 0, 1)
        #     else:
        #         print("Erreur: Trop de classes ou une seule classe pour un mappage simple à (0,1). SLIM pourrait échouer.")


        # Entraîner le modèle SLIM
        # Les hyperparamètres de SLIMClassifier peuvent nécessiter un ajustement.
        # alpha est le paramètre de régularisation L0 (complexité du modèle).
        # lambda_1 est le paramètre de régularisation L1 (coefficients).
        # Par défaut, SLIMClassifier utilise CPLEX ou un solveur MIP. S'ils ne sont pas installés,
        # il peut utiliser une heuristique ou échouer.
        # Pour une version plus simple et rapide, on peut utiliser peu d'itérations,
        # mais cela peut affecter la qualité.
        surrogate_model = SLIMClassifier(alpha=0.01, n_epochs=100, random_state=42) # n_epochs pour l'heuristique interne si pas de solveur MIP
        
        # SLIMClassifier de imodels peut être sensible au type de données.
        # S'assurer que X est un numpy array de float.
        X_slim = X.values.astype(float) if isinstance(X, pd.DataFrame) else np.array(X).astype(float)
        
        surrogate_model.fit(X_slim, y_distilled)
        print("Modèle surrogate RiskSLIM (SLIMClassifier) entraîné.")
        print("Coefficients du modèle SLIM :")
        # Afficher les coefficients (le "scorecard")
        for i, feature_name in enumerate(X.columns if isinstance(X, pd.DataFrame) else [f"feature_{j}" for j in range(X_slim.shape[1])]):
            if surrogate_model.model.coef_[0, i] != 0: # Afficher seulement les features avec des poids non nuls
                print(f"  {feature_name}: {surrogate_model.model.coef_[0, i]:.2f}")
        print(f"  Intercept: {surrogate_model.model.intercept_[0]:.2f}")
        
        return surrogate_model

    except NotFittedError:
        print("Erreur : Le modèle boîte noire n'est pas entraîné. Veuillez l'entraîner avant d'utiliser RiskSLIM.")
        return None
    except Exception as e:
        print(f"Une erreur est survenue lors de l'entraînement du surrogate RiskSLIM : {e}")
        import traceback
        traceback.print_exc()
        # SLIMClassifier peut parfois avoir des problèmes avec certains solveurs ou types de données.
        print("Conseil : Vérifiez que les données d'entrée X sont numériques et que les pseudo-labels y_distilled sont binaires (0/1 ou -1/1).")
        print("Si vous utilisez un solveur MIP comme CPLEX ou Gurobi, assurez-vous qu'il est correctement installé et licencié.")
        return None

# --- 🧪 Fonctions d'évaluation bonus ---

def evaluate_accuracy(model, X, y_true):
    """
    Évalue l'accuracy d'un modèle par rapport aux vrais labels.

    Args:
        model: Le modèle à évaluer (doit avoir une méthode `predict`).
        X (pd.DataFrame): Les données d'entrée.
        y_true (pd.Series or np.array): Les vrais labels.

    Returns:
        float: L'accuracy du modèle. Retourne None en cas d'erreur.
    """
    if model is None:
        print("Erreur d'évaluation : Le modèle fourni est None.")
        return None
    if not hasattr(model, "predict"):
        print(f"Erreur d'évaluation : Le modèle {type(model)} ne possède pas de méthode 'predict'.")
        return None
        
    print(f"Évaluation de l'accuracy du modèle {type(model).__name__}...")
    try:
        y_pred = model.predict(X)
        acc = accuracy_score(y_true, y_pred)
        print(f"Accuracy par rapport à y_true : {acc:.4f}")
        return acc
    except Exception as e:
        print(f"Erreur lors de l'évaluation de l'accuracy : {e}")
        return None

def evaluate_fidelity(model, blackbox_model, X):
    """
    Évalue la fidélité d'un modèle surrogate par rapport aux prédictions du modèle boîte noire.

    Args:
        model: Le modèle surrogate à évaluer (doit avoir une méthode `predict`).
        blackbox_model: Le modèle boîte noire de référence.
        X (pd.DataFrame): Les données d'entrée.

    Returns:
        float: La fidélité du modèle surrogate (accuracy par rapport aux prédictions de la boîte noire).
               Retourne None en cas d'erreur.
    """
    if model is None:
        print("Erreur d'évaluation de la fidélité : Le modèle surrogate fourni est None.")
        return None
    if blackbox_model is None:
        print("Erreur d'évaluation de la fidélité : Le modèle boîte noire fourni est None.")
        return None
    if not hasattr(model, "predict"):
        print(f"Erreur d'évaluation de la fidélité : Le modèle surrogate {type(model)} ne possède pas de méthode 'predict'.")
        return None
    if not hasattr(blackbox_model, "predict"):
        print(f"Erreur d'évaluation de la fidélité : Le modèle boîte noire {type(blackbox_model)} ne possède pas de méthode 'predict'.")
        return None

    print(f"Évaluation de la fidélité du modèle {type(model).__name__} par rapport à {type(blackbox_model).__name__}...")
    try:
        # Prédictions du modèle surrogate
        y_pred_surrogate = model.predict(X)
        
        # Prédictions du modèle boîte noire (pseudo-labels)
        y_pred_blackbox = blackbox_model.predict(X)
        
        fidelity = accuracy_score(y_pred_blackbox, y_pred_surrogate)
        print(f"Fidélité (similarité des prédictions) : {fidelity:.4f}")
        return fidelity
    except Exception as e:
        print(f"Erreur lors de l'évaluation de la fidélité : {e}")
        return None

# --- Exemple d'utilisation (à décommenter et adapter par l'utilisateur) ---
if __name__ == '__main__':
    print("--- Début de l'exemple d'utilisation ---")

    # 0. Préparation des données et du modèle (simulation)
    # L'utilisateur doit remplacer ces chemins par les siens.
    # Assurez-vous que 'dummy_data.csv' et 'dummy_blackbox_model.pkl' existent
    # ou remplacez par vos propres fichiers.

    # Création de données et d'un modèle factices pour l'exemple
    from sklearn.datasets import make_classification
    from sklearn.model_selection import train_test_split
    from sklearn.ensemble import RandomForestClassifier # Modèle boîte noire exemple

    X_data, y_data = make_classification(n_samples=500, n_features=10, n_informative=5, n_redundant=2, random_state=42)
    X_df = pd.DataFrame(X_data, columns=[f'feature_{i}' for i in range(X_data.shape[1])])
    y_series = pd.Series(y_data, name='target')

    # Sauvegarder les données factices
    X_df.to_csv('dummy_data.csv', index=False)
    # y_series est utilisé pour l'évaluation de l'accuracy, pas directement par les fonctions de distillation.

    # Entraîner et sauvegarder un modèle boîte noire factice
    blackbox_model_instance = RandomForestClassifier(n_estimators=50, random_state=42)
    blackbox_model_instance.fit(X_df, y_series)
    joblib.dump(blackbox_model_instance, 'dummy_blackbox_model.pkl')
    print("Données et modèle boîte noire factices créés et sauvegardés ('dummy_data.csv', 'dummy_blackbox_model.pkl').")

    # Chemins vers les fichiers (à adapter par l'utilisateur)
    csv_file_path = 'dummy_data.csv' # Remplacez par le chemin de votre fichier CSV
    model_file_path = 'dummy_blackbox_model.pkl' # Remplacez par le chemin de votre fichier .pkl

    # Charger les données et le modèle
    X_input = load_data(csv_file_path)
    blackbox_model_loaded = load_blackbox_model(model_file_path)

    # Noms des features (important pour LIME)
    if not X_input.empty:
        feature_names_list = X_input.columns.tolist()
    else:
        feature_names_list = [] # ou une liste par défaut si X_input est vide

    # Vérifier que tout est chargé correctement avant de continuer
    if X_input.empty or blackbox_model_loaded is None or not feature_names_list:
        print("\nErreur lors du chargement des données ou du modèle. Arrêt de l'exemple.")
    else:
        print(f"\nDonnées chargées : {X_input.shape}")
        print(f"Modèle boîte noire chargé : {type(blackbox_model_loaded).__name__}")
        print(f"Noms des features : {feature_names_list}")

        # 1. Distillation Globale
        print("\n--- Test de la Distillation Globale ---")
        lr_surrogate = distill_with_logistic_regression(X_input, blackbox_model_loaded)
        if lr_surrogate:
            print(f"Modèle de Régression Logistique distillé : {lr_surrogate}")
            evaluate_accuracy(lr_surrogate, X_input, y_series) # y_series sont les vrais labels
            evaluate_fidelity(lr_surrogate, blackbox_model_loaded, X_input)

        dt_surrogate = distill_with_decision_tree(X_input, blackbox_model_loaded, max_depth=4)
        if dt_surrogate:
            print(f"\nModèle d'Arbre de Décision distillé : {dt_surrogate}")
            evaluate_accuracy(dt_surrogate, X_input, y_series)
            evaluate_fidelity(dt_surrogate, blackbox_model_loaded, X_input)
            
            # Visualisation de l'arbre (optionnel, nécessite graphviz)
            try:
                from sklearn.tree import export_graphviz
                import graphviz
                dot_data = export_graphviz(dt_surrogate, out_file=None, 
                                         feature_names=feature_names_list,  
                                         class_names=[str(i) for i in np.unique(y_series)], # Assurez-vous que les noms de classe sont des str
                                         filled=True, rounded=True,  
                                         special_characters=True)  
                graph = graphviz.Source(dot_data)  
                graph.render("decision_tree_surrogate") # Sauvegarde en fichier
                print("\nPour visualiser l'arbre, vous pouvez décommenter graph.render() ou afficher graph directement si dans un notebook.")
                # Dans un notebook Jupyter, `graph` s'afficherait.
            except ImportError:
                print("\nGraphviz non installé. Impossible de visualiser l'arbre de décision.")
            except Exception as e_graph:
                print(f"\nErreur lors de la tentative de visualisation de l'arbre : {e_graph}")


        # 2. LIME Globalisé
        print("\n--- Test de LIME Globalisé ---")
        if LIME_AVAILABLE:
            # Utiliser un plus petit nombre d'échantillons pour l'exemple pour que ce soit plus rapide
            # S'assurer que X_input n'est pas vide
            num_lime_expl = min(50, X_input.shape[0]) if not X_input.empty else 0
            
            if num_lime_expl > 0:
                 # Déterminer le mode basé sur la sortie du modèle (simpliste)
                try:
                    pred_sample = blackbox_model_loaded.predict(X_input.head(1))
                    if hasattr(blackbox_model_loaded, 'predict_proba'):
                         lime_mode = 'classification'
                    elif isinstance(pred_sample[0], (int, str, bool, np.integer, np.bool_)): # Suppose classification si discret
                         lime_mode = 'classification' # Peut nécessiter predict_proba pour LIME
                         print("Avertissement LIME: Le modèle n'a pas predict_proba, LIME pour classification pourrait être moins optimal.")
                    else: # Suppose régression si continu
                         lime_mode = 'regression'
                except Exception:
                    lime_mode = 'classification' # Par défaut
                    print("Avertissement LIME: Impossible de déterminer le mode automatiquement, utilisation de 'classification'.")


                global_weights_lime = global_lime_weights(X_input, blackbox_model_loaded, 
                                                          feature_names_list, 
                                                          num_samples_lime=num_lime_expl,
                                                          mode=lime_mode)
                if global_weights_lime is not None and not global_weights_lime.empty:
                    print("\nPoids LIME Globaux (Top 5) :")
                    print(global_weights_lime.head())
                    plot_lime_weights(global_weights_lime, top_n=10)
                else:
                    print("Aucun poids LIME global n'a été calculé.")
            else:
                print("Pas assez d'échantillons dans X_input pour exécuter LIME globalisé.")
        else:
            print("LIME non disponible, test sauté.")

        # 3. RiskSLIM (approximatif)
        print("\n--- Test de RiskSLIM (approximatif) ---")
        if RISKSLIM_AVAILABLE:
            riskslim_surrogate = train_riskslim_surrogate(X_input, blackbox_model_loaded)
            if riskslim_surrogate:
                print(f"\nModèle RiskSLIM (approximatif) entraîné : {riskslim_surrogate}")
                evaluate_accuracy(riskslim_surrogate, X_input.values.astype(float), y_series) # SLIM peut nécessiter un array numpy
                evaluate_fidelity(riskslim_surrogate, blackbox_model_loaded, X_input.values.astype(float))
        else:
            print("imodels (pour SLIMClassifier) non disponible, test sauté.")

    print("\n--- Fin de l'exemple d'utilisation ---")